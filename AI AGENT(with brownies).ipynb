{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T16:22:30.277407Z",
     "start_time": "2025-03-05T16:20:22.419605Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools import tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    temperature=0.7\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aliza\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "GroqError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mGroqError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m load_dotenv()\n\u001B[32m     15\u001B[39m groq_api_key = os.getenv(\u001B[33m\"\u001B[39m\u001B[33mGROQ_API_KEY\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m llm = \u001B[43mChatGroq\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgroq_api_key\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroq_api_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mllama3-70b-8192\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.7\u001B[39;49m\n\u001B[32m     21\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001B[39m, in \u001B[36mSerializable.__init__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args: Any, **kwargs: Any) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    124\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:411\u001B[39m, in \u001B[36mChatGroq.validate_environment\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    409\u001B[39m sync_specific: Dict[\u001B[38;5;28mstr\u001B[39m, Any] = {\u001B[33m\"\u001B[39m\u001B[33mhttp_client\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.http_client}\n\u001B[32m    410\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.client:\n\u001B[32m--> \u001B[39m\u001B[32m411\u001B[39m     \u001B[38;5;28mself\u001B[39m.client = \u001B[43mgroq\u001B[49m\u001B[43m.\u001B[49m\u001B[43mGroq\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mclient_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43msync_specific\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m.chat.completions\n\u001B[32m    414\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.async_client:\n\u001B[32m    415\u001B[39m     async_specific: Dict[\u001B[38;5;28mstr\u001B[39m, Any] = {\u001B[33m\"\u001B[39m\u001B[33mhttp_client\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.http_async_client}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\_client.py:84\u001B[39m, in \u001B[36mGroq.__init__\u001B[39m\u001B[34m(self, api_key, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[39m\n\u001B[32m     82\u001B[39m     api_key = os.environ.get(\u001B[33m\"\u001B[39m\u001B[33mGROQ_API_KEY\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     83\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m GroqError(\n\u001B[32m     85\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     86\u001B[39m     )\n\u001B[32m     87\u001B[39m \u001B[38;5;28mself\u001B[39m.api_key = api_key\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m base_url \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mGroqError\u001B[39m: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T12:05:56.955622Z",
     "start_time": "2025-03-05T12:05:56.228283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#To load pdf files\n",
    "\n",
    "pdf_folder_path = \"./Data/RagFiles\"\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    pdf_folder_path,\n",
    "    glob=\"*.pdf\",\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} PDF documents from {pdf_folder_path}\")\n"
   ],
   "id": "673643695aa5629f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 81 PDF documents from ./Data/RagFiles\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T12:05:57.547487Z",
     "start_time": "2025-03-05T12:05:57.536976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "print(f\"After splitting, we have {len(docs)} chunks total.\")\n"
   ],
   "id": "1cc06a4f6a8efcc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitting, we have 338 chunks total.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T12:06:03.918851Z",
     "start_time": "2025-03-05T12:05:58.231542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SentenceTransformerEmbeddings:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text])[0].tolist()\n",
    "\n",
    "embedding_func = SentenceTransformerEmbeddings()\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding=embedding_func, persist_directory=\"./chroma_db\")\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ],
   "id": "d030100120de4b53",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T12:06:03.943968Z",
     "start_time": "2025-03-05T12:06:03.919854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tool\n",
    "def add(input_str: str) -> str:\n",
    "    \"\"\"Add two numbers from a string like 1, 2.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a + b)\n",
    "\n",
    "@tool\n",
    "def subtract(input_str: str) -> str:\n",
    "    \"\"\"Subtract two numbers from a string like 5, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a - b)\n",
    "\n",
    "@tool\n",
    "def multiply(input_str: str) -> str:\n",
    "    \"\"\"Multiply two numbers from a string like 2, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a * b)\n",
    "\n",
    "@tool\n",
    "def divide(input_str: str) -> str:\n",
    "    \"\"\"Divide two numbers from a string like 6, 2.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    if b == 0:\n",
    "        return \"Error: Division by zero\"\n",
    "    return str(a / b)\n",
    "\n",
    "@tool\n",
    "def power(input_str: str) -> str:\n",
    "    \"\"\"Raise one number to another from a string like 2, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a ** b)\n",
    "\n",
    "@tool\n",
    "def modulus(input_str: str) -> str:\n",
    "    \"\"\"Compute the remainder for 'a mod b' from a string like 5, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a % b)\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web using SerpAPI for the given query.\n",
    "    Returns a summary of the top results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        serpapi = SerpAPIWrapper()\n",
    "        return serpapi.run(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def pdf_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant PDF content based on the query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant PDF content\n",
    "    \n",
    "    Returns:\n",
    "        str: Chunks of relevant PDF content\n",
    "    \"\"\"\n",
    "\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No relevant documents found for query: {query}\"\n",
    "\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def summarize_file(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes PDF files related to the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant PDF files\n",
    "    \n",
    "    Returns:\n",
    "        str: Comprehensive summary of matching PDF files\n",
    "    \"\"\"\n",
    "    all_docs = docs\n",
    "\n",
    "    combined_text = \" \".join([doc.page_content for doc in all_docs])\n",
    "\n",
    "    summary_prompt = f\"\"\"\n",
    "    Provide a comprehensive summary of all documents related to {query}, \n",
    "    covering the entire content of the knowledge base:\n",
    "\n",
    "    {combined_text[:20000]}  # Limit to avoid token issues\n",
    "\n",
    "    Key points to cover:\n",
    "    - Overall context and scope\n",
    "    - Main concepts and principles\n",
    "    - Significant insights\n",
    "    - Practical applications\n",
    "    - Important technical details\n",
    "\n",
    "    Detailed Summary:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        summary = llm.invoke(summary_prompt).content\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"Error generating summary: {str(e)}\"\n",
    "    \n",
    "@tool\n",
    "def notes_file(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Makes notes of the PDF files related to the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant PDF files\n",
    "    \n",
    "    Returns:\n",
    "        str: Notes from matching PDF files\n",
    "    \"\"\"\n",
    "    all_docs = docs\n",
    "    chunk_notes = []\n",
    "\n",
    "    for doc in all_docs:\n",
    "        chunk_prompt = f\"\"\"\n",
    "        Provide a concise set of structured notes for the following document content\n",
    "        related to {query}. Present the notes in clear bullet points.\n",
    "\n",
    "        Document Excerpt:\n",
    "        {doc.page_content[:5000]}\n",
    "\n",
    "        Bullet-Point Notes:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            note = llm.invoke(chunk_prompt).content\n",
    "            chunk_notes.append(note)\n",
    "        except Exception as e:\n",
    "            chunk_notes.append(f\"Error generating notes for a chunk: {str(e)}\")\n",
    "\n",
    "    combined_notes_prompt = f\"\"\"\n",
    "    The following are notes from different document chunks related to {query}. \n",
    "    Summarize them into a single structured set of notes with key takeaways.\n",
    "\n",
    "    Individual Notes:\n",
    "    {\"\\n\\n\".join(chunk_notes)}\n",
    "\n",
    "    Final Consolidated Notes:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        final_notes = llm.invoke(combined_notes_prompt).content\n",
    "        return final_notes\n",
    "    except Exception as e:\n",
    "        return f\"Error generating final notes: {str(e)}\"\n",
    "\n",
    "    \n",
    "tools = [add, subtract, multiply, divide, power, modulus, web_search, pdf_rag, summarize_file, notes_file]"
   ],
   "id": "b9f20714adc8b480",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T12:06:03.950868Z",
     "start_time": "2025-03-05T12:06:03.943968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    output_key=\"output\"\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an AI agent with access to these tools:\n",
    "{tool_names}\n",
    "\n",
    "Tools:\n",
    "{tools}\n",
    "\n",
    "When you need to use a tool, respond exactly in this format:\n",
    "\n",
    "Thoughts: [Reasoning]\n",
    "Action: [tool name]\n",
    "Action Input:[tool input]\n",
    "\n",
    "“If you take an action, do not produce a final answer. If you produce a final answer, do not produce an action.”\n",
    "\n",
    "Thoughts: [Reasoning]\n",
    "\n",
    "Final Answer: [answer here]\n",
    "\n",
    "User Question: {user_input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\",\n",
    "    input_variables=[\"tool_names\", \"tools\", \"user_input\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt_template.partial(\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "        tools=\"\\n\".join([f\"{t.name}: {t.description}\" for t in tools])\n",
    "    )\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ],
   "id": "8293e4bbaee0c825",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliza\\AppData\\Local\\Temp\\ipykernel_27232\\2542868426.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T12:05:15.201724Z",
     "start_time": "2025-03-05T12:00:55.847197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = agent_executor.invoke({\"user_input\": \"can you make a summary on the convo in the pdf files\"})\n",
    "print(response)"
   ],
   "id": "8a42496d705095c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThoughts: The user is asking me to summarize the conversation in the PDF files. I will use the summarize_file tool to achieve this.\n",
      "\n",
      "Action: summarize_file\n",
      "Action Input: convo\u001B[0m\u001B[38;5;200m\u001B[1;3mHere is a comprehensive summary of the provided text, covering the key points, main concepts, significant insights, practical applications, and important technical details:\n",
      "\n",
      "**Overall Context and Scope:**\n",
      "The text is an introduction to deep learning, a subfield of artificial intelligence (AI) that involves the use of neural networks to analyze and interpret data. The authors aim to provide a comprehensive overview of deep learning, its principles, and its applications.\n",
      "\n",
      "**Main Concepts and Principles:**\n",
      "\n",
      "1. **Artificial Intelligence (AI):** AI involves creating machines that can think and learn like humans.\n",
      "2. **Machine Learning:** Machine learning is a type of AI that enables computers to learn from data without being explicitly programmed.\n",
      "3. **Deep Learning:** Deep learning is a subset of machine learning that involves the use of neural networks to analyze and interpret data.\n",
      "4. **Representation Learning:** Representation learning involves learning to represent data in a way that is useful for machine learning models.\n",
      "5. **Autoencoders:** Autoencoders are neural networks that learn to compress and reconstruct data, allowing them to discover new representations of the data.\n",
      "\n",
      "**Significant Insights:**\n",
      "\n",
      "1. **Difficulty of AI:** AI is difficult because it requires machines to learn from experience and understand the world in the same way humans do.\n",
      "2. **Importance of Representation:** The choice of representation is critical in machine learning, as it can significantly impact the performance of the model.\n",
      "3. **Deep Learning as a Solution:** Deep learning provides a solution to the problem of representation by allowing machines to learn complex concepts from simpler ones.\n",
      "\n",
      "**Practical Applications:**\n",
      "\n",
      "1. **Image Recognition:** Deep learning has been successfully applied to image recognition tasks, such as recognizing objects in images.\n",
      "2. **Speech Recognition:** Deep learning has also been applied to speech recognition tasks, such as transcribing spoken language into text.\n",
      "3. **Natural Language Processing:** Deep learning has been used in natural language processing tasks, such as language translation and text summarization.\n",
      "\n",
      "**Important Technical Details:**\n",
      "\n",
      "1. **Neural Networks:** Neural networks are composed of multiple layers of interconnected nodes (neurons) that process and transform inputs into outputs.\n",
      "2. **Activation Functions:** Activation functions are used to introduce non-linearity into neural networks, allowing them to learn complex patterns in data.\n",
      "3. **Backpropagation:** Backpropagation is an algorithm used to train neural networks by minimizing the error between the predicted output and the actual output.\n",
      "\n",
      "Overall, the text provides a comprehensive introduction to deep learning, covering its principles, applications, and technical details.\u001B[0m\u001B[32;1m\u001B[1;3mThoughts: The user is asking me to summarize the conversation in the PDF files, but I realize that there is no conversation in the PDF files. The user might be referring to the conversation we just had. I will make notes on the conversation using the notes_file tool.\n",
      "\n",
      "Action: notes_file\n",
      "Action Input: convo\u001B[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m response = \u001B[43magent_executor\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser_input\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcan you make a summary on the convo in the pdf files\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    169\u001B[39m     run_manager.on_chain_error(e)\n\u001B[32m--> \u001B[39m\u001B[32m170\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    171\u001B[39m run_manager.on_chain_end(outputs)\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    158\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_inputs(inputs)\n\u001B[32m    159\u001B[39m     outputs = (\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    162\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call(inputs)\n\u001B[32m    163\u001B[39m     )\n\u001B[32m    165\u001B[39m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] = \u001B[38;5;28mself\u001B[39m.prep_outputs(\n\u001B[32m    166\u001B[39m         inputs, outputs, return_only_outputs\n\u001B[32m    167\u001B[39m     )\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1624\u001B[39m, in \u001B[36mAgentExecutor._call\u001B[39m\u001B[34m(self, inputs, run_manager)\u001B[39m\n\u001B[32m   1622\u001B[39m \u001B[38;5;66;03m# We now enter the agent loop (until it returns something).\u001B[39;00m\n\u001B[32m   1623\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m._should_continue(iterations, time_elapsed):\n\u001B[32m-> \u001B[39m\u001B[32m1624\u001B[39m     next_step_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_take_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1625\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1626\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1627\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1628\u001B[39m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1629\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1630\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1631\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(next_step_output, AgentFinish):\n\u001B[32m   1632\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._return(\n\u001B[32m   1633\u001B[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001B[32m   1634\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1332\u001B[39m, in \u001B[36mAgentExecutor._take_next_step\u001B[39m\u001B[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[39m\n\u001B[32m   1321\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_take_next_step\u001B[39m(\n\u001B[32m   1322\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1323\u001B[39m     name_to_tool_map: Dict[\u001B[38;5;28mstr\u001B[39m, BaseTool],\n\u001B[32m   (...)\u001B[39m\u001B[32m   1327\u001B[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1328\u001B[39m ) -> Union[AgentFinish, List[Tuple[AgentAction, \u001B[38;5;28mstr\u001B[39m]]]:\n\u001B[32m   1329\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._consume_next_step(\n\u001B[32m   1330\u001B[39m         \u001B[43m[\u001B[49m\n\u001B[32m   1331\u001B[39m \u001B[43m            \u001B[49m\u001B[43ma\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m1332\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1333\u001B[39m \u001B[43m                \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1334\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1335\u001B[39m \u001B[43m                \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1336\u001B[39m \u001B[43m                \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1337\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1338\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1339\u001B[39m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m   1340\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1415\u001B[39m, in \u001B[36mAgentExecutor._iter_next_step\u001B[39m\u001B[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[39m\n\u001B[32m   1413\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m agent_action\n\u001B[32m   1414\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m agent_action \u001B[38;5;129;01min\u001B[39;00m actions:\n\u001B[32m-> \u001B[39m\u001B[32m1415\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_perform_agent_action\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1416\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43magent_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\n\u001B[32m   1417\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1437\u001B[39m, in \u001B[36mAgentExecutor._perform_agent_action\u001B[39m\u001B[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001B[39m\n\u001B[32m   1435\u001B[39m         tool_run_kwargs[\u001B[33m\"\u001B[39m\u001B[33mllm_prefix\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1436\u001B[39m     \u001B[38;5;66;03m# We then call the tool on the tool input to get an observation\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1437\u001B[39m     observation = \u001B[43mtool\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1438\u001B[39m \u001B[43m        \u001B[49m\u001B[43magent_action\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtool_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1439\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1440\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1441\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1442\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtool_run_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1443\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1444\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1445\u001B[39m     tool_run_kwargs = \u001B[38;5;28mself\u001B[39m._action_agent.tool_run_logging_kwargs()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:763\u001B[39m, in \u001B[36mBaseTool.run\u001B[39m\u001B[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001B[39m\n\u001B[32m    761\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m error_to_raise:\n\u001B[32m    762\u001B[39m     run_manager.on_tool_error(error_to_raise)\n\u001B[32m--> \u001B[39m\u001B[32m763\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m error_to_raise\n\u001B[32m    764\u001B[39m output = _format_output(content, artifact, tool_call_id, \u001B[38;5;28mself\u001B[39m.name, status)\n\u001B[32m    765\u001B[39m run_manager.on_tool_end(output, color=color, name=\u001B[38;5;28mself\u001B[39m.name, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:732\u001B[39m, in \u001B[36mBaseTool.run\u001B[39m\u001B[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m config_param := _get_runnable_config_param(\u001B[38;5;28mself\u001B[39m._run):\n\u001B[32m    731\u001B[39m     tool_kwargs = tool_kwargs | {config_param: config}\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m response = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mtool_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtool_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.response_format == \u001B[33m\"\u001B[39m\u001B[33mcontent_and_artifact\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    734\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(response) != \u001B[32m2\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\tools\\structured.py:89\u001B[39m, in \u001B[36mStructuredTool._run\u001B[39m\u001B[34m(self, config, run_manager, *args, **kwargs)\u001B[39m\n\u001B[32m     87\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m config_param := _get_runnable_config_param(\u001B[38;5;28mself\u001B[39m.func):\n\u001B[32m     88\u001B[39m         kwargs[config_param] = config\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     90\u001B[39m msg = \u001B[33m\"\u001B[39m\u001B[33mStructuredTool does not support sync invocation.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(msg)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 143\u001B[39m, in \u001B[36mnotes_file\u001B[39m\u001B[34m(query)\u001B[39m\n\u001B[32m    133\u001B[39m chunk_prompt = \u001B[33mf\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m    134\u001B[39m \u001B[33mProvide a concise set of structured notes for the following document content\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[33mrelated to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Present the notes in clear bullet points.\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    140\u001B[39m \u001B[33mBullet-Point Notes:\u001B[39m\n\u001B[32m    141\u001B[39m \u001B[33m\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m    142\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m143\u001B[39m     note = \u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_prompt\u001B[49m\u001B[43m)\u001B[49m.content\n\u001B[32m    144\u001B[39m     chunk_notes.append(note)\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:285\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    274\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    275\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    276\u001B[39m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[32m   (...)\u001B[39m\u001B[32m    280\u001B[39m     **kwargs: Any,\n\u001B[32m    281\u001B[39m ) -> BaseMessage:\n\u001B[32m    282\u001B[39m     config = ensure_config(config)\n\u001B[32m    283\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    284\u001B[39m         ChatGeneration,\n\u001B[32m--> \u001B[39m\u001B[32m285\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    286\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    288\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    289\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    290\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    293\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    295\u001B[39m     ).message\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:861\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    853\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    854\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    855\u001B[39m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[32m   (...)\u001B[39m\u001B[32m    858\u001B[39m     **kwargs: Any,\n\u001B[32m    859\u001B[39m ) -> LLMResult:\n\u001B[32m    860\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m861\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:691\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    688\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[32m    689\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    690\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m691\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    692\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    693\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    694\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    695\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    696\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    697\u001B[39m         )\n\u001B[32m    698\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    699\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:926\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    924\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    925\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m926\u001B[39m         result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    927\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    928\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    929\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    930\u001B[39m         result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:480\u001B[39m, in \u001B[36mChatGroq._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    475\u001B[39m message_dicts, params = \u001B[38;5;28mself\u001B[39m._create_message_dicts(messages, stop)\n\u001B[32m    476\u001B[39m params = {\n\u001B[32m    477\u001B[39m     **params,\n\u001B[32m    478\u001B[39m     **kwargs,\n\u001B[32m    479\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m480\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._create_chat_result(response)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:322\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    166\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m    167\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    168\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m    198\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m    199\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m    200\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    201\u001B[39m \u001B[33;03m    Creates a model response for the given chat conversation.\u001B[39;00m\n\u001B[32m    202\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    320\u001B[39m \u001B[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[32m    321\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/openai/v1/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    333\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    334\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    339\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    340\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    342\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    343\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    344\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    345\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    346\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1266\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1252\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1253\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1254\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1261\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1262\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1263\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1264\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1265\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1266\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\_base_client.py:958\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[39m\n\u001B[32m    955\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    956\u001B[39m     retries_taken = \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m958\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    959\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    961\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    962\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    963\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    964\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1046\u001B[39m, in \u001B[36mSyncAPIClient._request\u001B[39m\u001B[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[39m\n\u001B[32m   1044\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries > \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._should_retry(err.response):\n\u001B[32m   1045\u001B[39m     err.response.close()\n\u001B[32m-> \u001B[39m\u001B[32m1046\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1047\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1048\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1049\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1050\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresponse_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43merr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m.\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1051\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1052\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1053\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1055\u001B[39m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[32m   1056\u001B[39m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[32m   1057\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err.response.is_closed:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1095\u001B[39m, in \u001B[36mSyncAPIClient._retry_request\u001B[39m\u001B[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[39m\n\u001B[32m   1091\u001B[39m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[32m   1092\u001B[39m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[32m   1093\u001B[39m time.sleep(timeout)\n\u001B[32m-> \u001B[39m\u001B[32m1095\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1096\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1097\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1098\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1099\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1100\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1101\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\groq\\_base_client.py:994\u001B[39m, in \u001B[36mSyncAPIClient._request\u001B[39m\u001B[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[39m\n\u001B[32m    991\u001B[39m log.debug(\u001B[33m\"\u001B[39m\u001B[33mSending HTTP Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m, request.method, request.url)\n\u001B[32m    993\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m994\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    995\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    996\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_should_stream_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    997\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    998\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    999\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m httpx.TimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m   1000\u001B[39m     log.debug(\u001B[33m\"\u001B[39m\u001B[33mEncountered httpx.TimeoutException\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001B[39m, in \u001B[36mClient.send\u001B[39m\u001B[34m(self, request, stream, auth, follow_redirects)\u001B[39m\n\u001B[32m    910\u001B[39m \u001B[38;5;28mself\u001B[39m._set_timeout(request)\n\u001B[32m    912\u001B[39m auth = \u001B[38;5;28mself\u001B[39m._build_request_auth(request, auth)\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001B[39m, in \u001B[36mClient._send_handling_auth\u001B[39m\u001B[34m(self, request, auth, follow_redirects, history)\u001B[39m\n\u001B[32m    939\u001B[39m request = \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    947\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    948\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001B[39m, in \u001B[36mClient._send_handling_redirects\u001B[39m\u001B[34m(self, request, follow_redirects, history)\u001B[39m\n\u001B[32m    976\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mrequest\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    977\u001B[39m     hook(request)\n\u001B[32m--> \u001B[39m\u001B[32m979\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    981\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mresponse\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001B[39m, in \u001B[36mClient._send_single_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m   1009\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1010\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1011\u001B[39m     )\n\u001B[32m   1013\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=request):\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m     response = \u001B[43mtransport\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, SyncByteStream)\n\u001B[32m   1018\u001B[39m response.request = request\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001B[39m, in \u001B[36mHTTPTransport.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    237\u001B[39m req = httpcore.Request(\n\u001B[32m    238\u001B[39m     method=request.method,\n\u001B[32m    239\u001B[39m     url=httpcore.URL(\n\u001B[32m   (...)\u001B[39m\u001B[32m    247\u001B[39m     extensions=request.extensions,\n\u001B[32m    248\u001B[39m )\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp.stream, typing.Iterable)\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[32m    255\u001B[39m     status_code=resp.status,\n\u001B[32m    256\u001B[39m     headers=resp.headers,\n\u001B[32m    257\u001B[39m     stream=ResponseStream(resp.stream),\n\u001B[32m    258\u001B[39m     extensions=resp.extensions,\n\u001B[32m    259\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    253\u001B[39m         closing = \u001B[38;5;28mself\u001B[39m._assign_requests_to_connections()\n\u001B[32m    255\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_connections(closing)\n\u001B[32m--> \u001B[39m\u001B[32m256\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    258\u001B[39m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[32m    260\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, typing.Iterable)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    232\u001B[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001B[32m    234\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    235\u001B[39m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m236\u001B[39m     response = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[32m    240\u001B[39m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[32m    241\u001B[39m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[32m    242\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    243\u001B[39m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[32m    244\u001B[39m     pool_request.clear_connection()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001B[39m, in \u001B[36mHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mself\u001B[39m._connect_failed = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mresponse_closed\u001B[39m\u001B[33m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    135\u001B[39m         \u001B[38;5;28mself\u001B[39m._response_closed()\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[32m     98\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mreceive_response_headers\u001B[39m\u001B[33m\"\u001B[39m, logger, request, kwargs\n\u001B[32m     99\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    100\u001B[39m     (\n\u001B[32m    101\u001B[39m         http_version,\n\u001B[32m    102\u001B[39m         status,\n\u001B[32m    103\u001B[39m         reason_phrase,\n\u001B[32m    104\u001B[39m         headers,\n\u001B[32m    105\u001B[39m         trailing_data,\n\u001B[32m--> \u001B[39m\u001B[32m106\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    107\u001B[39m     trace.return_value = (\n\u001B[32m    108\u001B[39m         http_version,\n\u001B[32m    109\u001B[39m         status,\n\u001B[32m    110\u001B[39m         reason_phrase,\n\u001B[32m    111\u001B[39m         headers,\n\u001B[32m    112\u001B[39m     )\n\u001B[32m    114\u001B[39m network_stream = \u001B[38;5;28mself\u001B[39m._network_stream\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_headers\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    174\u001B[39m timeout = timeouts.get(\u001B[33m\"\u001B[39m\u001B[33mread\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Response):\n\u001B[32m    179\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    214\u001B[39m     event = \u001B[38;5;28mself\u001B[39m._h11_state.next_event()\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11.NEED_DATA:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_stream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    218\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data == \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\GDSC ML Task\\pythonProject\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001B[39m, in \u001B[36mSyncStream.read\u001B[39m\u001B[34m(self, max_bytes, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m._sock.settimeout(timeout)\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\ssl.py:1232\u001B[39m, in \u001B[36mSSLSocket.recv\u001B[39m\u001B[34m(self, buflen, flags)\u001B[39m\n\u001B[32m   1228\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m flags != \u001B[32m0\u001B[39m:\n\u001B[32m   1229\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1230\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m %\n\u001B[32m   1231\u001B[39m             \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1232\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1233\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1234\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().recv(buflen, flags)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\ssl.py:1105\u001B[39m, in \u001B[36mSSLSocket.read\u001B[39m\u001B[34m(self, len, buffer)\u001B[39m\n\u001B[32m   1103\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sslobj.read(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[32m   1104\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1105\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sslobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1106\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[32m   1107\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m x.args[\u001B[32m0\u001B[39m] == SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.suppress_ragged_eofs:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f8cfdddfe0f79dab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
