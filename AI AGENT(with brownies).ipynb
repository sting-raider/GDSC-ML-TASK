{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T17:34:02.792867Z",
     "start_time": "2025-03-05T17:34:02.076509Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools import tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.7\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T17:34:05.863199Z",
     "start_time": "2025-03-05T17:34:05.790778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#To load pdf files\n",
    "\n",
    "pdf_folder_path = \"./Data/RagFiles\"\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    pdf_folder_path,\n",
    "    glob=\"*.pdf\",\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} PDF documents from {pdf_folder_path}\")\n"
   ],
   "id": "673643695aa5629f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 PDF documents from ./Data/RagFiles\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T17:34:07.685887Z",
     "start_time": "2025-03-05T17:34:07.680880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "print(f\"After splitting, we have {len(docs)} chunks total.\")\n"
   ],
   "id": "1cc06a4f6a8efcc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitting, we have 8 chunks total.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SentenceTransformerEmbeddings:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text])[0].tolist()\n",
    "\n",
    "embedding_func = SentenceTransformerEmbeddings()\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding=embedding_func, persist_directory=\"./chroma_db\")\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ],
   "id": "d030100120de4b53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T17:34:10.278759Z",
     "start_time": "2025-03-05T17:34:10.252488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tool\n",
    "def add(input_str: str) -> str:\n",
    "    \"\"\"Add two numbers from a string like 1, 2.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a + b)\n",
    "\n",
    "@tool\n",
    "def subtract(input_str: str) -> str:\n",
    "    \"\"\"Subtract two numbers from a string like 5, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a - b)\n",
    "\n",
    "@tool\n",
    "def multiply(input_str: str) -> str:\n",
    "    \"\"\"Multiply two numbers from a string like 2, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a * b)\n",
    "\n",
    "@tool\n",
    "def divide(input_str: str) -> str:\n",
    "    \"\"\"Divide two numbers from a string like 6, 2.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    if b == 0:\n",
    "        return \"Error: Division by zero\"\n",
    "    return str(a / b)\n",
    "\n",
    "@tool\n",
    "def power(input_str: str) -> str:\n",
    "    \"\"\"Raise one number to another from a string like 2, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a ** b)\n",
    "\n",
    "@tool\n",
    "def modulus(input_str: str) -> str:\n",
    "    \"\"\"Compute the remainder for 'a mod b' from a string like 5, 3.\"\"\"\n",
    "    a_str, b_str = input_str.split(\",\")\n",
    "    a = float(a_str.strip())\n",
    "    b = float(b_str.strip())\n",
    "    return str(a % b)\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web using SerpAPI for the given query.\n",
    "    Returns a summary of the top results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        serpapi = SerpAPIWrapper()\n",
    "        return serpapi.run(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def pdf_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve relevant PDF content based on the query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant content\n",
    "    \n",
    "    Returns:\n",
    "        str: Chunks of relevant content\n",
    "    \"\"\"\n",
    "\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No relevant documents found for query: {query}\"\n",
    "\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def summarize_file(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes files related to the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant files\n",
    "    \n",
    "    Returns:\n",
    "        str: Comprehensive summary of matching files\n",
    "    \"\"\"\n",
    "    all_docs = docs\n",
    "    chunk_summary=[]\n",
    "\n",
    "    for doc in all_docs:\n",
    "        chunk_prompt = f\"\"\"\n",
    "        Provide a summary for the following document content\n",
    "        related to {query}. Present the summary in detail.\n",
    "\n",
    "        Document Excerpt:\n",
    "        {doc.page_content[:5000]}\n",
    "\n",
    "        Detailed Summary:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            note = llm.invoke(chunk_prompt).content\n",
    "            chunk_summary.append(note)\n",
    "        except Exception as e:\n",
    "            chunk_summary.append(f\"Error generating notes for a chunk: {str(e)}\")\n",
    "\n",
    "    combined_notes_prompt = f\"\"\"\n",
    "    The following are summaries from different document chunks related to {query}. \n",
    "    Summarize them into a single structured set.\n",
    "\n",
    "    Individual Summaries:\n",
    "    {\"\\n\\n\".join(chunk_summary)}\n",
    "\n",
    "    Final Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        final_summary = llm.invoke(combined_notes_prompt).content\n",
    "        return final_summary\n",
    "    except Exception as e:\n",
    "        return f\"Error generating final notes: {str(e)}\"\n",
    "    \n",
    "@tool\n",
    "def notes_file(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Makes notes of the files related to the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant files\n",
    "    \n",
    "    Returns:\n",
    "        str: Notes from matching files\n",
    "    \"\"\"\n",
    "    all_docs = docs\n",
    "    chunk_notes = []\n",
    "\n",
    "    for doc in all_docs:\n",
    "        chunk_prompt = f\"\"\"\n",
    "        Provide a concise set of structured notes for the following document content\n",
    "        related to {query}. Present the notes in clear bullet points.\n",
    "\n",
    "        Document Excerpt:\n",
    "        {doc.page_content[:5000]}\n",
    "\n",
    "        Bullet-Point Notes:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            note = llm.invoke(chunk_prompt).content\n",
    "            chunk_notes.append(note)\n",
    "        except Exception as e:\n",
    "            chunk_notes.append(f\"Error generating notes for a chunk: {str(e)}\")\n",
    "\n",
    "    combined_notes_prompt = f\"\"\"\n",
    "    The following are notes from different document chunks related to {query}. \n",
    "    Summarize them into a single structured set of notes with key takeaways.\n",
    "\n",
    "    Individual Notes:\n",
    "    {\"\\n\\n\".join(chunk_notes)}\n",
    "\n",
    "    Final Notes:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        final_notes = llm.invoke(combined_notes_prompt).content\n",
    "        return final_notes\n",
    "    except Exception as e:\n",
    "        return f\"Error generating final notes: {str(e)}\"\n",
    "\n",
    "    \n",
    "tools = [add, subtract, multiply, divide, power, modulus, web_search, pdf_rag, summarize_file, notes_file]"
   ],
   "id": "b9f20714adc8b480",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T17:47:12.904899Z",
     "start_time": "2025-03-05T17:47:12.898599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    output_key=\"output\"\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an AI agent with access to these tools:\n",
    "{tool_names}\n",
    "\n",
    "Tools:\n",
    "{tools}\n",
    "\n",
    "When you need to use a tool, respond exactly in this format:\n",
    "\n",
    "Thoughts: [Reasoning]\n",
    "Action: [tool name]\n",
    "Action Input:[tool input]\n",
    "\n",
    "\"pdf_rag, summarize_file, notes_file take priority over web_search.\"\n",
    "\"Use web_search only if any of the present tools are unable to provide a relevant answer.\"\n",
    "“If you take an action, do not produce a final answer. If you produce a final answer, do not produce an action.”\n",
    "\n",
    "Thoughts: [Reasoning]\n",
    "\n",
    "Final Answer: [answer here]\n",
    "\n",
    "User Question: {user_input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\",\n",
    "    input_variables=[\"tool_names\", \"tools\", \"user_input\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt_template.partial(\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "        tools=\"\\n\".join([f\"{t.name}: {t.description}\" for t in tools])\n",
    "    )\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ],
   "id": "8293e4bbaee0c825",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T17:53:00.306438Z",
     "start_time": "2025-03-05T17:52:55.902746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = agent_executor.invoke({\"user_input\": \"can you do  1.346 to the power 7.289\"})\n",
    "print(response)"
   ],
   "id": "8a42496d705095c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThoughts: The user asked to raise 1.346 to the power 7.289. I need to find a way to perform this operation.\n",
      "\n",
      "Action: power\n",
      "Action Input: 1.346, 7.289\u001B[0m\u001B[33;1m\u001B[1;3m8.721866632573068\u001B[0m\u001B[32;1m\u001B[1;3mThoughts: The operation was performed successfully. I will now provide the result of the power operation.\n",
      "\n",
      "Final Answer: 8.722\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'user_input': 'can you do  1.346 to the power 7.289', 'history': 'Current summary: \\nThe human asks the AI to do addition between 1.346 and 7.289, to which the AI responds with the result of 8.635.\\n\\nNew lines of conversation:\\nHuman: can you do multiplication between 1.346 and 7.289\\nAI: 9.810994\\n\\nNew summary: \\nThe human asks the AI to perform mathematical operations, starting with addition between 1.346 and 7.289, resulting in 8.635, and then proceeds to ask for multiplication between the same numbers, receiving a result of 9.810994.', 'output': '8.722', 'intermediate_steps': [(AgentAction(tool='power', tool_input='1.346, 7.289', log='Thoughts: The user asked to raise 1.346 to the power 7.289. I need to find a way to perform this operation.\\n\\nAction: power\\nAction Input: 1.346, 7.289'), '8.721866632573068')]}\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5904f32d8e35dccb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
