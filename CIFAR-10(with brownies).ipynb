{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Importing required libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#checking if its using my gpu or cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Splitting the Dataset (Train & Validation Sets)\n",
    "\n",
    "data_dir = \"./Data/train\"\n",
    "csv_path = \"./Data/trainLabels.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "class_names = sorted(df['label'].unique())\n",
    "class_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "print(f\"Train samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n"
   ],
   "id": "895e9e51be414d8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#preprocessing images to be compatible with the VGG16 model\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #makes the size of the image 224x224 (cuz the vgg model has been trained on it)\n",
    "    \n",
    "    #Brownies: Data augmentation\n",
    "    \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], #model was trained on the imagenet dataset so these are the mean and std RGB values of the images.\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), #to convert the image to a pyTorch tensor (ie bring it from range 0-255 to 0-1)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_dir, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image_id = row['id']\n",
    "        label_str = row['label']\n",
    "\n",
    "        img_path = os.path.join(self.data_dir, f\"{image_id}.png\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = class_map[label_str]\n",
    "        return image, label\n",
    "\n",
    "train_dataset = ImageDataset(train_df, data_dir, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, data_dir, transform=val_transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "71afc2dd745e5b37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_model = models.vgg16(weights='IMAGENET1K_V1') #brownie:loading a pretrained model \n",
    "\n",
    "for param in base_model.features[:20].parameters():\n",
    "    param.requires_grad = False #freezing of the first 20 layers in the model which handle feature extraction and don't need to be retrained as they've already been trained on a large dataset and know basic features.\n",
    "\n",
    "in_features = base_model.classifier[6].in_features #1000 neurons for imagenet FC layer\n",
    "base_model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, len(class_names))    \n",
    ")\n",
    "\n",
    "model = base_model.to(device)\n",
    "\n",
    "print(model)"
   ],
   "id": "2de5d264b4ce387f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "#brownie: learning rate scheduler.\n",
    "#reduces the learning rate when a metric like val_loss starts stagnates instead of improving.\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "num_epochs = 11\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "writer = SummaryWriter(log_dir='Logs/with_brownies')\n"
   ],
   "id": "c16a0983663e3c05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_epoch_acc = 100.0 * correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in val_loader:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            \n",
    "            val_running_loss += val_loss.item() * val_images.size(0)\n",
    "            \n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_epoch_acc = 100.0 * val_correct / val_total\n",
    "    \n",
    "    scheduler.step(val_epoch_loss)\n",
    "    \n",
    "    train_losses.append(train_epoch_loss)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    train_accs.append(train_epoch_acc)\n",
    "    val_accs.append(val_epoch_acc)\n",
    "    \n",
    "    writer.add_scalar('Loss/Train', train_epoch_loss, epoch)\n",
    "    writer.add_scalar('Loss/Val', val_epoch_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Train', train_epoch_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/Val', val_epoch_acc, epoch)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_acc:.2f}% \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.2f}%\")\n",
    "    \n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_brownie_model.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "            \n",
    "writer.close()\n"
   ],
   "id": "9631df90c825679e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(\"best_brownie_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_images, val_labels in val_loader:\n",
    "        val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "        outputs = model(val_images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, average='weighted')\n",
    "rec = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"Validation Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.3f}, Recall: {rec:.3f}, F1-score: {f1:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ],
   "id": "bedf7bbb917837ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bb024b1efe84290c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
